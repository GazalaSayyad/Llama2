# Llama2
Llama 2: Empowering Conversations with Elegance and Precision

Llama 2 release brings new pretrained and fine-tuned LLMs, ranging from 7B to 70B parameters. These models offer improvements over Llama 1, being trained on 40% more tokens and having a longer context length of 4k tokens. The 70B model uses grouped-query attention for faster inference. The most exciting part is the fine-tuned models (Llama 2-Chat), optimized for dialogue using RLHF. They outperform most open models and are comparable to ChatGPT in helpfulness and safety benchmarks. Check out the paper for more details.


## Related Articles

- [Llma2](https://medium.com/@gazalashaikh999/llama-2-empowering-conversations-with-elegance-and-precision-747b8100744c) - A brief description of the post.
- paper https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/
